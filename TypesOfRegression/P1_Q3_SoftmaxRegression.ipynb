{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "1e990529",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Student ID 1002080520\n",
    "import numpy as np\n",
    "from numpy import loadtxt\n",
    "import csv\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "#CODE TO TAKE THE DATA AND STORE IN THE VARIABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "8690c86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('q2_a_training.csv')\n",
    "csvreader = csv.reader(file, delimiter = \",\")\n",
    "data = []\n",
    "for row in csvreader:\n",
    "    data.append(row)\n",
    "\n",
    "train_data = []\n",
    "for i in range(0 , len(data)):\n",
    "    col= []\n",
    "    for j in range(0,len(data[i])):\n",
    "        if j==len(data[i])-1:\n",
    "            col.append(data[i][j])\n",
    "        else:\n",
    "            col.append(data[i][j])\n",
    "    train_data.append(col)\n",
    "file.close()\n",
    "X_train = []\n",
    "Y_train = []\n",
    "for i in range(len(train_data)):\n",
    "    cols = []\n",
    "    for j in range(0,len(train_data[i])):\n",
    "        if(j==len(train_data[i])-1):\n",
    "            Y_train.append(train_data[i][j])\n",
    "        else:\n",
    "            cols.append(train_data[i][j])\n",
    "    X_train.append(cols)   \n",
    "for i in range(0,len(X_train)):\n",
    "    for j in range(0,len(X_train[i])):\n",
    "        X_train[i][j]=float(X_train[i][j])\n",
    "X_train = np.array(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "6296b74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('q2_cde_dataset.csv')\n",
    "csvreader = csv.reader(file, delimiter = \",\")\n",
    "data = []\n",
    "for row in csvreader:\n",
    "    data.append(row)\n",
    "\n",
    "train_data = []\n",
    "for i in range(0 , len(data)):\n",
    "    col= []\n",
    "    for j in range(0,len(data[i])):\n",
    "        if j==len(data[i])-1:\n",
    "            col.append(data[i][j])\n",
    "        else:\n",
    "            col.append(data[i][j])\n",
    "    train_data.append(col)\n",
    "file.close()\n",
    "X_cde_train = []\n",
    "Y_cde_train = []\n",
    "for i in range(len(train_data)):\n",
    "    cols = []\n",
    "    for j in range(0,len(train_data[i])):\n",
    "        if(j==len(train_data[i])-1):\n",
    "            Y_cde_train.append(train_data[i][j])\n",
    "        else:\n",
    "            cols.append(train_data[i][j])\n",
    "    X_cde_train.append(cols)   \n",
    "for i in range(0,len(X_cde_train)):\n",
    "    for j in range(0,len(X_cde_train[i])):\n",
    "        X_cde_train[i][j]=float(X_cde_train[i][j])\n",
    "X_cde_train = np.array(X_cde_train)\n",
    "Y_cde_train = np.array(Y_cde_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "ecf684d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('q2_a_test_data.csv')\n",
    "csvreader = csv.reader(file, delimiter = \",\")\n",
    "data = []\n",
    "for row in csvreader:\n",
    "    data.append(row)\n",
    "\n",
    "train_data = []\n",
    "for i in range(0 , len(data)):\n",
    "    col= []\n",
    "    for j in range(0,len(data[i])):\n",
    "        if j==len(data[i])-1:\n",
    "            col.append(data[i][j])\n",
    "        else:\n",
    "            col.append(data[i][j])\n",
    "    train_data.append(col)\n",
    "file.close()\n",
    "X_test = []\n",
    "Y_test = []\n",
    "for i in range(len(train_data)):\n",
    "    cols = []\n",
    "    for j in range(0,len(train_data[i])):\n",
    "        cols.append(train_data[i][j])\n",
    "    X_test.append(cols)   \n",
    "for i in range(0,len(X_test)):\n",
    "    for j in range(0,len(X_test[i])):\n",
    "        X_test[i][j]=float(X_test[i][j])\n",
    "X_test = np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "1e10aca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We are coding all the possible functions required to perform softmax_regression\n",
    "def initialize_weights(X,Y):\n",
    "    z = np.ones((len(X[1]),np.max(Y)+1))\n",
    "    return z\n",
    "\n",
    "def set_labels_int(Y):\n",
    "    for i in range(0,len(Y)):\n",
    "        if Y[i] ==\" Metal\":\n",
    "            Y[i]=0\n",
    "        if Y[i] == \" Plastic\":\n",
    "            Y[i]=1\n",
    "        if Y[i] == \" Ceramic\":\n",
    "            Y[i]=2\n",
    "    return Y\n",
    "\n",
    "def reset_labels(Y):\n",
    "    y=[]\n",
    "    for i in range(0,len(Y)):\n",
    "        if Y[i] == 0:\n",
    "            y.append(\" Metal\")\n",
    "        if Y[i] == 1:\n",
    "            y.append(\" Plastic\")\n",
    "        if Y[i] == 2:\n",
    "            y.append(\" Ceramic\")\n",
    "    return y\n",
    "\n",
    "def set_one_hot(Y_train): \n",
    "    y_train=[]\n",
    "    for i in range(0,len(Y_train)):\n",
    "        arr = []\n",
    "        for j in range(0,np.max(Y_train)+1):\n",
    "            if Y_train[i] == j:\n",
    "                arr.append(1)\n",
    "            else:\n",
    "                arr.append(0)\n",
    "        y_train.append(arr)\n",
    "    return y_train\n",
    "\n",
    "def training(X,Y,w,learning_rate=0.1,epochs=1):\n",
    "    for i in range(0,epochs):\n",
    "        z = np.dot(X,w)\n",
    "        z = np.exp(z)/np.sum(np.exp(z), axis=0)\n",
    "        z = np.add(z,(-Y))\n",
    "        gradient = np.dot(X.T,z)\n",
    "        w = w+learning_rate*gradient\n",
    "    return w\n",
    "def predict(X,w):\n",
    "    ans = np.dot(X,w)\n",
    "    ans = np.exp(ans) / np.sum(np.exp(ans), axis=0)\n",
    "    ans = np.argmax(ans, axis=1)\n",
    "    return ans\n",
    "def predict1(X,w):\n",
    "    ans = np.dot(X,w)\n",
    "    ans = np.exp(ans) / np.sum(np.exp(ans), axis=0)\n",
    "    ans = np.argmax(ans, axis=0)\n",
    "    return ans\n",
    "\n",
    "def accuracy(X,Y):\n",
    "    c_match = 0\n",
    "    for i in range(0,len(X)):\n",
    "        if X[i]==Y[i]:\n",
    "            c_match+=1\n",
    "    c = (c_match/len(X))*100\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "94036c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' Plastic', ' Plastic', ' Ceramic', ' Plastic']\n"
     ]
    }
   ],
   "source": [
    "#Now we will train for X_train data\n",
    "X_train = np.array(X_train)\n",
    "#Converting the labels into int for Y_train\n",
    "\n",
    "Y_train = np.array(set_labels_int(Y_train))\n",
    "#Now we will intialize the weight matrix\n",
    "\n",
    "weight = initialize_weights(X_train,Y_train)\n",
    "\n",
    "#Now we will create hot_ones matrix for Y_train\n",
    "\n",
    "Y_train_hot_ones = np.array(set_one_hot(Y_train))\n",
    "\n",
    "\n",
    "#Now we will perform training with respect to softmax_regression\n",
    "\n",
    "trained_weight = training(X_train,Y_train_hot_ones,weight)\n",
    "Y_predict = predict(X_test,trained_weight)\n",
    "print(reset_labels(Y_predict))\n",
    "#Now we will predict for test data with given trained Parameters\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "76f0c56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_test for test data\n",
    "#X_cde_training for cross validation\n",
    "#X_train for simple training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "9df81225",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y1/l51j2m6x13qcr8qy4_s2qjz80000gn/T/ipykernel_86289/1492214005.py:3: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_cde_train = y_cde_train.astype(np.int)\n"
     ]
    }
   ],
   "source": [
    "#We will perform leave one out validation\n",
    "y_cde_train = set_labels_int(Y_cde_train)\n",
    "y_cde_train = y_cde_train.astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "67179979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(0,len(X_cde_train)):\n",
    "#     a = X_cde_train[0:i]\n",
    "#     a1 = X_cde_train[i+1:len(X_cde_train)]\n",
    "#     a = np.vstack((a,a1))\n",
    "#     b= np.delete(y_cde_train,[i])\n",
    "#     #Now we have our a , b matrix for the data and now carry on leave on out validation\n",
    "#     print(a)\n",
    "#     print(b)\n",
    "#     #Intializing the weights\n",
    "    \n",
    "#     weight_lov =  np.ones((len(a[0]),np.max(b)+1)\n",
    "    \n",
    "#     #Creating hot one matrix from b\n",
    "#     # Training the weight matrix\n",
    "                          \n",
    "    \n",
    "#     trained_weight_lov = training(a,b_hot_one,weight_lov)\n",
    "    \n",
    "#     b_predict = predict(X_cde_train[i],trained_weight_lov)\n",
    "#     lov_predict.append(b_predict)\n",
    "# print(lov_predict)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "aafc9973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' Ceramic', ' Metal', ' Ceramic', ' Ceramic', ' Metal', ' Metal', ' Metal', ' Metal', ' Metal', ' Metal', ' Ceramic', ' Metal', ' Metal', ' Metal', ' Metal', ' Metal', ' Ceramic', ' Metal', ' Ceramic', ' Metal', ' Metal', ' Metal', ' Ceramic', ' Metal', ' Metal', ' Ceramic', ' Ceramic', ' Ceramic', ' Metal', ' Metal', ' Metal', ' Ceramic', ' Metal', ' Metal', ' Ceramic', ' Metal', ' Metal', ' Metal', ' Metal', ' Metal', ' Metal', ' Ceramic', ' Metal', ' Metal', ' Metal', ' Ceramic', ' Metal', ' Metal', ' Ceramic', ' Metal', ' Metal', ' Ceramic', ' Metal', ' Metal', ' Ceramic', ' Metal', ' Metal', ' Ceramic', ' Ceramic', ' Metal', ' Metal', ' Metal', ' Metal', ' Metal', ' Metal', ' Metal', ' Metal', ' Metal', ' Metal', ' Ceramic', ' Ceramic', ' Ceramic', ' Ceramic', ' Ceramic', ' Ceramic', ' Metal', ' Metal', ' Metal', ' Ceramic', ' Ceramic', ' Metal', ' Ceramic', ' Metal', ' Metal', ' Ceramic', ' Ceramic', ' Metal', ' Metal', ' Metal', ' Metal', ' Metal', ' Metal', ' Metal', ' Metal', ' Metal', ' Metal', ' Metal', ' Metal', ' Metal', ' Metal', ' Metal', ' Metal', ' Metal', ' Metal', ' Metal', ' Metal', ' Metal', ' Metal', ' Metal', ' Metal', ' Metal', ' Metal', ' Metal', ' Metal', ' Metal', ' Metal', ' Metal', ' Metal', ' Metal', ' Metal']\n",
      "Accuracy for Leave One Out Validation is 50.0%\n"
     ]
    }
   ],
   "source": [
    "lov_predict =[]\n",
    "for i in range(0,len(X_cde_train)):\n",
    "    a1 = X_cde_train[0:i]\n",
    "    a2= X_cde_train[i+1:len(X_cde_train)]\n",
    "    a = np.vstack((a1,a2))\n",
    "    b = np.delete(y_cde_train,[i])\n",
    "    weight_lov = np.ones((len(a[0]),np.max(b)+1))\n",
    "    b_hot_ones = np.array(set_one_hot(b))\n",
    "    trained_weight_lov = training(a,b_hot_ones,weight_lov)\n",
    "    b_predict = predict1(X_cde_train[i],trained_weight_lov)\n",
    "    lov_predict.append(b_predict)\n",
    "print(reset_labels(lov_predict))\n",
    "c_match = 0\n",
    "for i in range(0,len(lov_predict)):\n",
    "    if lov_predict[i]==y_cde_train[i]:\n",
    "        c_match+=1\n",
    "c = (c_match/len(lov_predict))*100\n",
    "\n",
    "print(\"Accuracy for Leave One Out Validation is \"+str(c)+\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "90d516bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[2 0 2 2 1 1 1 1 1 1 2 0 0 0 0 0 2 1 2 1 0 0 2 0 0 2 2 2 1 0 0 2 0 1 2 0 0\n",
      " 1 1 1 1 2 0 1 1 2 0 0 2 1 1 2 0 0 2 0 1 2 2 0 0 1 1 1 0 1 1 0 0 2 2 2 2 2\n",
      " 2 0 1 1 2 2 0 2 0 1 2 2 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1]\n",
      "Accuracy for Leave One Out Validation is 25.0%\n"
     ]
    }
   ],
   "source": [
    "#We will repeat the same procedure after removing the 4 th attribute of the data\n",
    "\n",
    "X_cde_4_train = np.delete(X_cde_train, [3], axis =1)\n",
    "lov_predict_4 =[]\n",
    "for i in range(0,len(X_cde_4_train)):\n",
    "    a1 = X_cde_4_train[0:i]\n",
    "    a2= X_cde_4_train[i+1:len(X_cde_4_train)]\n",
    "    a = np.vstack((a1,a2))\n",
    "    b = np.delete(y_cde_train,[i])\n",
    "    weight_lov = np.ones((len(a[0]),np.max(b)+1))\n",
    "    b_hot_ones = np.array(set_one_hot(b))\n",
    "    trained_weight_lov = training(a,b_hot_ones,weight_lov)\n",
    "    b_predict = predict1(X_cde_4_train[i],trained_weight_lov)\n",
    "    lov_predict_4.append(b_predict)\n",
    "print(lov_predict_4)\n",
    "print(y_cde_train)\n",
    "c_match = 0\n",
    "for i in range(0,len(lov_predict)):\n",
    "    if lov_predict_4[i]==y_cde_train[i]:\n",
    "        c_match+=1\n",
    "c = (c_match/len(lov_predict))*100\n",
    "\n",
    "print(\"Accuracy for Leave One Out Validation is \"+str(c)+\"%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd0144e",
   "metadata": {},
   "source": [
    "# PLEASE NOTE THAT I HAVE ALSO ATTACHED THE PREVIOUS ASSIGNMENT IN ORDER TO COMPARE THE RESULTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13362f4",
   "metadata": {},
   "source": [
    "# CONCLUSION\n",
    "\n",
    "QB) Now for leaving one out validation with all 4 attributes we have an accuracy of 50% whereas we had 52.55% in KNN model with K = 3 \n",
    "\n",
    "QC) Now when there are only 3 attributes we got amazing results for KNN model which is on average 80% whereas in Softmax Regression we only have 25% of accuracy.\n",
    "\n",
    "Now softmax regression is not more accurate then KNN as softmax works on the probability whereas KNN model does not require any assumptions about the underlying distribution of the data and can work well with imbalanced datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638c8584",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
